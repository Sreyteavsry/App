{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sreyteavsry/App/blob/master/Final_Version__2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdXy_KVNX4m5"
      },
      "source": [
        "**Importing the libraries**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colabcode\n",
        "!pip install fastapi\n"
      ],
      "metadata": {
        "id": "e_vQh4ff0xcq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e4310e9-f7a4-4ff6-e608-d2995dfa609c"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: colabcode in /usr/local/lib/python3.7/dist-packages (0.3.0)\n",
            "Requirement already satisfied: pyngrok>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from colabcode) (5.1.0)\n",
            "Requirement already satisfied: jupyterlab==3.0.7 in /usr/local/lib/python3.7/dist-packages (from colabcode) (3.0.7)\n",
            "Requirement already satisfied: nest-asyncio==1.4.3 in /usr/local/lib/python3.7/dist-packages (from colabcode) (1.4.3)\n",
            "Requirement already satisfied: uvicorn==0.13.1 in /usr/local/lib/python3.7/dist-packages (from colabcode) (0.13.1)\n",
            "Requirement already satisfied: tornado>=6.1.0 in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.0.7->colabcode) (6.2)\n",
            "Requirement already satisfied: jupyterlab-server~=2.0 in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.0.7->colabcode) (2.15.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.0.7->colabcode) (5.5.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.0.7->colabcode) (4.11.1)\n",
            "Requirement already satisfied: nbclassic~=0.2 in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.0.7->colabcode) (0.3.7)\n",
            "Requirement already satisfied: jupyter-server~=1.2 in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.0.7->colabcode) (1.18.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.0.7->colabcode) (21.3)\n",
            "Requirement already satisfied: jinja2>=2.10 in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.0.7->colabcode) (3.1.2)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.7/dist-packages (from uvicorn==0.13.1->colabcode) (0.13.0)\n",
            "Requirement already satisfied: click==7.* in /usr/local/lib/python3.7/dist-packages (from uvicorn==0.13.1->colabcode) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from uvicorn==0.13.1->colabcode) (4.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.10->jupyterlab==3.0.7->colabcode) (2.0.1)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (3.6.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (1.3.3)\n",
            "Requirement already satisfied: nbformat>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (5.4.0)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (1.8.0)\n",
            "Requirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (6.5.3)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.14.1)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (6.1.12)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (23.2.0)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (21.3.0)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.13.3)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (5.3.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.7/dist-packages (from anyio<4,>=3.1.0->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (2.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.7/dist-packages (from anyio<4,>=3.1.0->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=6.1.12->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (4.12.0)\n",
            "Requirement already satisfied: jsonschema>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (4.3.3)\n",
            "Requirement already satisfied: babel in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (2.10.3)\n",
            "Requirement already satisfied: json5 in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (0.9.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3.6->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (3.8.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (22.1.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (5.9.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (0.18.1)\n",
            "Requirement already satisfied: notebook-shim>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from nbclassic~=0.2->jupyterlab==3.0.7->colabcode) (0.1.0)\n",
            "Requirement already satisfied: notebook<7 in /usr/local/lib/python3.7/dist-packages (from nbclassic~=0.2->jupyterlab==3.0.7->colabcode) (5.3.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.4)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (1.1.1)\n",
            "Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (2.6.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (4.9.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (1.5.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (5.0.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.6.6)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (4.6.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.7/dist-packages (from nbconvert>=6.4.4->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.2.2)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat>=5.2.0->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (2.16.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from notebook<7->nbclassic~=0.2->jupyterlab==3.0.7->colabcode) (0.2.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from notebook<7->nbclassic~=0.2->jupyterlab==3.0.7->colabcode) (4.10.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok>=5.0.0->colabcode) (3.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->jupyter-client>=6.1.12->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (1.15.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.3->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.7/dist-packages (from argon2-cffi->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (21.2.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (2.21)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from babel->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (2022.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert>=6.4.4->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.5.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (57.4.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (1.0.18)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (4.4.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (0.8.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (0.7.5)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->jupyterlab==3.0.7->colabcode) (0.2.5)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->jupyterlab==3.0.7->colabcode) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (3.0.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.7/dist-packages (0.79.0)\n",
            "Requirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in /usr/local/lib/python3.7/dist-packages (from fastapi) (1.9.1)\n",
            "Requirement already satisfied: starlette==0.19.1 in /usr/local/lib/python3.7/dist-packages (from fastapi) (0.19.1)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from starlette==0.19.1->fastapi) (3.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0 in /usr/local/lib/python3.7/dist-packages (from starlette==0.19.1->fastapi) (4.1.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.7/dist-packages (from anyio<5,>=3.4.0->starlette==0.19.1->fastapi) (1.2.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.7/dist-packages (from anyio<5,>=3.4.0->starlette==0.19.1->fastapi) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from colabcode import ColabCode\n",
        "from fastapi import FastAPI\n",
        "app = FastAPI()\n",
        "@app.get(\"/\")\n",
        "async def read_root():\n",
        "  return {\"message\": \"Compound Identification\"}\n",
        "cc = ColabCode(port=12000, code=False)"
      ],
      "metadata": {
        "id": "sqCZ_hxf0_kP"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cc.run_app(app=app)"
      ],
      "metadata": {
        "id": "ArXQ-EEM1R8k"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "QBm7RA6x2BOv"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "GtPqs7I5XrGB"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import time\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ve4JX3noZ_Bn"
      },
      "source": [
        "**Checking for available GPU**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "HQRW5QgzYr_V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06ee2090-cd1e-44db-8cf3-53128c93ad63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on GPU\n"
          ]
        }
      ],
      "source": [
        "train_on_gpu = torch.cuda.is_available()\n",
        "if(train_on_gpu):\n",
        "  print(\"Training on GPU\")\n",
        "else:\n",
        "  print(\"No GPU available\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gf44TBLiCwsb"
      },
      "source": [
        "#Dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_O0dEogkC9D1"
      },
      "source": [
        "##Loading files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "6dcJaXeM31yo"
      },
      "outputs": [],
      "source": [
        "def compound_tag(str): #remove the combinded tags (compound words)\n",
        "    ls = ['n-[', 'o-[','v-[','v[','o[', 'n[' ,'a-[', 'a[','1[','.[','+[', '_n-','_n', '_v', '_o-','_o','_a-', '_a','_1-','_.-','_1', '_.']\n",
        "    #ls = ['o[', 'n[', 'n-[', 'o-[','v-[','v[','a-[', 'a[','1[','.[','+[',']n-',']n',']o-',']v-',']v',']o',']a-',']a',']1',']o-','].', ']+','_n', '_n-', '_v', '_o','_a','_1', '_.']\n",
        "    cm = [']n-',']n',']o-',']v-',']v',']o',']a-',']a',']1',']o-','].', ']+']\n",
        "    for i in ls:\n",
        "      str = str.replace(i,'')\n",
        "    for ii in cm:\n",
        "      str = str.replace(']', '_c')\n",
        "    return str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "CqgdM9UfqAya"
      },
      "outputs": [],
      "source": [
        "def cls(str): #remove the combinded tags (compound words)\n",
        "    ls = ['o[', 'n[', 'n-[', 'o-[','v-[','v[','a-[', 'a[','1[','.[','+[',']n-',']n',']o-',']v-',']v',']o',']a-',']a',']1',']o-','].', ']+']\n",
        "    for i in ls:\n",
        "      str = str.replace(i,'')\n",
        "    return str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "55E1dOLFDwtv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "248c5795-e090-4de1-e6ec-c6e74075c2ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "f_tok = open('/content/drive/MyDrive/Dataset/Khmer NLP/data_km.km-tok.txt', 'r', encoding ='utf-8')\n",
        "\n",
        "f_tag = open('/content/drive/MyDrive/Dataset/Khmer NLP/data_km.km-tag.txt', 'r', encoding ='utf-8')\n",
        "tok = [x.split() for x in f_tok] #split each sentence by space into word list\n",
        "postag = [x.split() for x in f_tag] #split each sentence by space into tag list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8GabosCGkbA"
      },
      "source": [
        "## Combining token&tag and removing number of sentence (ex: SNT.80188.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "-tomjCnoH3jV"
      },
      "outputs": [],
      "source": [
        "data = []\n",
        "tok_clean = []\n",
        "tag_clean = []\n",
        "tag_clean_all =[]\n",
        "for ii in range(len(tok)):\n",
        "# initializing lists  \n",
        "  tok_list = tok[ii]\n",
        "  tag_list = postag[ii]\n",
        "  tag_list_clean = [cls(i) for i in postag[ii]]\n",
        "  res = [i + '_'+ j for i, j in zip(tok_list, tag_list)]\n",
        "  res.pop(0)\n",
        "  data.append(res)\n",
        "  tok_clean.append(tok_list[1:])\n",
        "  tag_clean.append(tag_list[1:])\n",
        "  tag_clean_all.append(tag_list_clean[1:])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tag_clean_all[0])"
      ],
      "metadata": {
        "id": "fyntp4k4FdA7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3895cd30-aa2b-40a7-dbcb-815d241d1168"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['n', 'v-', 'v', 'o', 'n', 'n', 'o', 'n', 'n', 'o', 'n', 'v', 'n', 'n', 'n', 'n', 'o', 'n', 'n', 'v', 'n', '1', 'n', 'v', 'v-', 'n', 'n', 'n', 'n', 'n', 'n', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiYI_2kGycPJ"
      },
      "source": [
        "## List of characters and tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "YSafituJy52R"
      },
      "outputs": [],
      "source": [
        "KHCONST = list(u'កខគឃងចឆជឈញដឋឌឍណតថទធនបផពភមយរលវឝឞសហឡអឣឤឥឦឧឩឪឫឬឭឮឯឰឱឲឳ')\n",
        "KHVOWEL = list(u'឴឵ាិីឹឺុូួើឿៀេែៃោៅ\\u17c6\\u17c7\\u17c8')\n",
        "# subscript, diacritics\n",
        "KHSUB = list(u'្')\n",
        "KHDIAC = list(u\"\\u17c9\\u17ca\\u17cb\\u17cc\\u17cd\\u17ce\\u17cf\\u17d0\\u200b\") #MUUSIKATOAN, TRIISAP, BANTOC,ROBAT,\n",
        "KHSYM = list('៕។៛ៗ៚៙៘,.?-!') # add space\n",
        "KHNUMBER = list(u'០១២៣៤៥៦៧៨៩0123456789') # remove 0123456789\n",
        "ENGCHAR = list(u'abcdefghijklmnopqrstuvwxyz')\n",
        "ENGUPPERCHAR = list(u'ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
        "\n",
        "CHARS = ['PADDING'] + ['UNK']+ KHCONST + KHVOWEL + KHSUB + KHDIAC + KHSYM + KHNUMBER + ENGCHAR + ENGUPPERCHAR\n",
        "NOTAG = ['ns']\n",
        "BASICTAGS = list(('n','v', 'a', 'o'))\n",
        "AUXTAGS = list(('1', '.', '+'))\n",
        "MODIFIEDTAGS =list(('n-', 'v-', 'a-', 'o-'))\n",
        "COMPOUNDTAGS = list(('cn','cv', 'ca', 'co', 'cn-', 'cv-', 'ca-', 'co-', 'c1', 'c.', 'c+'))\n",
        "POSTAGS = ['PADDING']+ NOTAG + BASICTAGS + AUXTAGS + MODIFIEDTAGS + COMPOUNDTAGS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeV5XfoZy7X-"
      },
      "source": [
        "## Mapping char and tag to an index and vice versa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "3FR4X2RzzDG8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc12f1c6-e15d-4d7e-8490-34fe422042d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'PADDING': 0, 'ns': 1, 'n': 2, 'v': 3, 'a': 4, 'o': 5, '1': 6, '.': 7, '+': 8, 'n-': 9, 'v-': 10, 'a-': 11, 'o-': 12, 'cn': 13, 'cv': 14, 'ca': 15, 'co': 16, 'cn-': 17, 'cv-': 18, 'ca-': 19, 'co-': 20, 'c1': 21, 'c.': 22, 'c+': 23}\n"
          ]
        }
      ],
      "source": [
        "chars2idx = {o:i for i,o in enumerate(CHARS)}\n",
        "tags2idx = {o:i for i,o in enumerate(POSTAGS)}\n",
        "idx2tags = {i:o for i,o in enumerate(POSTAGS)}\n",
        "idx2chars = {i:o for i,o in enumerate(CHARS)}\n",
        "print(tags2idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36KFw3QMGRn3"
      },
      "source": [
        "##Generating characters with labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "Jw6oh-9xGgWk"
      },
      "outputs": [],
      "source": [
        "def gen_char_with_label(sentence, tags):\n",
        "    words = sentence\n",
        "    final_kccs = []\n",
        "    for word, tagss in zip(words, tags):\n",
        "        kccs = list(word)\n",
        "        labels = [cls(tagss) if (i==0 or k==\" \") else 'ns' for i, k in enumerate(word)]\n",
        "        final_kccs.extend(list(zip(kccs,labels)))\n",
        "    return final_kccs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "zrBaJIv0HRqE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e7acb17-1f95-4cf1-8984-d0fde9cece87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('អ', 'n'), ('៊', 'ns'), ('ី', 'ns'), ('ត', 'ns'), ('ា', 'ns'), ('ល', 'ns'), ('ី', 'ns'), ('ប', 'v-'), ('ា', 'ns'), ('ន', 'ns'), ('ឈ', 'v'), ('្', 'ns'), ('ន', 'ns'), ('ះ', 'ns'), ('ល', 'o'), ('ើ', 'ns'), ('ព', 'n'), ('័', 'ns'), ('រ', 'ns'), ('ទ', 'ns'), ('ុ', 'ns'), ('យ', 'ns'), ('ហ', 'ns'), ('្', 'ns'), ('គ', 'ns'), ('ា', 'ns'), ('ល', 'ns'), ('់', 'ns'), ('3', 'n'), ('1', 'ns'), ('-', 'ns'), ('5', 'ns'), ('ក', 'o'), ('្', 'ns'), ('ន', 'ns'), ('ុ', 'ns'), ('ង', 'ns'), ('ប', 'n'), ('៉', 'ns'), ('ូ', 'ns'), ('ល', 'ns'), ('C', 'n'), ('ន', 'o'), ('ៃ', 'ns'), ('ព', 'n'), ('ិ', 'ns'), ('ធ', 'ns'), ('ី', 'ns'), ('ប', 'v'), ('្', 'ns'), ('រ', 'ns'), ('ក', 'ns'), ('ួ', 'ns'), ('ត', 'ns'), ('ព', 'n'), ('ា', 'ns'), ('ន', 'ns'), ('រ', 'n'), ('ង', 'ns'), ('្', 'ns'), ('វ', 'ns'), ('ា', 'ns'), ('ន', 'ns'), ('់', 'ns'), ('ព', 'n'), ('ិ', 'ns'), ('ភ', 'ns'), ('ព', 'ns'), ('ល', 'n'), ('ោ', 'ns'), ('ក', 'ns'), ('ន', 'o'), ('ៃ', 'ns'), ('ក', 'n'), ('ី', 'ns'), ('ឡ', 'ns'), ('ា', 'ns'), ('ប', 'n'), ('ា', 'ns'), ('ល', 'ns'), ('់', 'ns'), ('ឱ', 'v'), ('ប', 'ns'), ('ឆ', 'n'), ('្', 'ns'), ('ន', 'ns'), ('ា', 'ns'), ('ំ', 'ns'), ('2', '1'), ('0', 'ns'), ('0', 'ns'), ('7', 'ns'), ('ដ', 'n'), ('ែ', 'ns'), ('ល', 'ns'), ('ប', 'v'), ('្', 'ns'), ('រ', 'ns'), ('ព', 'ns'), ('្', 'ns'), ('រ', 'ns'), ('ឹ', 'ns'), ('ត', 'ns'), ('្', 'ns'), ('ត', 'ns'), ('ន', 'v-'), ('ៅ', 'ns'), ('ប', 'n'), ('៉', 'ns'), ('ា', 'ns'), ('ស', 'ns'), ('ឌ', 'n'), ('េ', 'ns'), ('ស', 'ns'), ('ប', 'n'), ('្', 'ns'), ('រ', 'ns'), ('ី', 'ns'), ('ន', 'ns'), ('ក', 'n'), ('្', 'ns'), ('រ', 'ns'), ('ុ', 'ns'), ('ង', 'ns'), ('ប', 'n'), ('៉', 'ns'), ('ា', 'ns'), ('រ', 'ns'), ('ី', 'ns'), ('ស', 'ns'), ('ប', 'n'), ('ា', 'ns'), ('រ', 'ns'), ('ា', 'ns'), ('ំ', 'ns'), ('ង', 'ns'), ('។', '.')]\n"
          ]
        }
      ],
      "source": [
        "print(gen_char_with_label(tok_clean[0], tag_clean[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "pSi0D1OVpfmn"
      },
      "outputs": [],
      "source": [
        "def sentence_with_compound(sentence, tag):\n",
        "  sentence_with_compounds = []\n",
        "  start = 0\n",
        "  end = 0\n",
        "  pos_com = []\n",
        "  for i, j in enumerate(tag):\n",
        "    if j.find(\"[\") !=-1:\n",
        "      start = i\n",
        "      if tag[start+1].find(\"]\") !=-1:\n",
        "        end = start+2\n",
        "      elif tag[start+2].find(\"]\") !=-1:\n",
        "        end = start+3\n",
        "      elif tag[start+3].find(\"]\") !=-1:\n",
        "        end = start+4\n",
        "      compound = ''.join(sentence[start:end])\n",
        "      pos_com.append('c'+compound_tag(j))\n",
        "      sentence_with_compounds.append(compound)\n",
        "    if i not in range(start,end):\n",
        "        sentence_with_compounds.append(sentence[i])\n",
        "        pos_com.append(j)\n",
        "  return sentence_with_compounds, pos_com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "KQBSPp9y1E7D"
      },
      "outputs": [],
      "source": [
        "sentence_with_compounds = [sentence_with_compound(sentence, tags) for i, (sentence, tags) in enumerate(zip(tok_clean, tag_clean))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "lwgWTBYioRcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f366c779-f1e0-4a8e-bf41-472ed6c9e0d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['អ៊ីតាលី', 'បាន', 'ឈ្នះ', 'លើ', 'ព័រទុយហ្គាល់', '31-5', 'ក្នុង', 'ប៉ូលC', 'នៃ', 'ពិធីប្រកួត', 'ពានរង្វាន់', 'ពិភពលោក', 'នៃ', 'កីឡាបាល់ឱប', 'ឆ្នាំ2007', 'ដែល', 'ប្រព្រឹត្ត', 'នៅ', 'ប៉ាសឌេសប្រីន', 'ក្រុងប៉ារីស', 'បារាំង', '។']\n",
            "['n', 'v-', 'v', 'o', 'n', 'n', 'o', 'cn', 'o', 'cn', 'cn', 'cn', 'o', 'cn', 'cn', 'n', 'v', 'v-', 'cn', 'cn', 'n', '.']\n",
            "19\n",
            "['ញូវ', 'សាឡេន', 'បាន', 'នាំ', 'មុខ', 'នៅ', 'ក្នុង', 'ក្រុម', 'មាន', '១០', 'ពិន្ទុ', 'ឈរ', 'លើ', 'ស្កុតឡេន', 'ដោយសារ', 'ពិន្ទុ', 'ខុស', 'គ្នា', '។']\n",
            "['ញូវ_n[n', 'សាឡេន_n]n', 'បាន_v-', 'នាំ_v[v', 'មុខ_n]v', 'នៅ_v-', 'ក្នុង_v-', 'ក្រុម_n', 'មាន_v', '១០_a[1', 'ពិន្ទុ_n]a', 'ឈរ_v', 'លើ_o', 'ស្កុតឡេន_n', 'ដោយសារ_o', 'ពិន្ទុ_n', 'ខុស_a[a', 'គ្នា_n]a', '។_.']\n"
          ]
        }
      ],
      "source": [
        "print(sentence_with_compounds[0][0])\n",
        "print(sentence_with_compounds[0][1])\n",
        "print(len(tok_clean[7]))\n",
        "print(tok_clean[7])\n",
        "print(data[7])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "nN5oX56TIcpd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58c58abf-9605-469a-af0e-eac832e086f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['អ៊ីតាលី_n', 'បាន_v-', 'ឈ្នះ_v', 'លើ_o', 'ព័រទុយហ្គាល់_n', '31-5_n', 'ក្នុង_o', 'ប៉ូល_n[n', 'C_n]n', 'នៃ_o', 'ពិធី_n[n', 'ប្រកួត_v]n', 'ពាន_n[n', 'រង្វាន់_n]n', 'ពិភព_n[n', 'លោក_n]n', 'នៃ_o', 'កីឡា_n[n', 'បាល់_n', 'ឱប_v]n', 'ឆ្នាំ_n[n', '2007_1]n', 'ដែល_n', 'ប្រព្រឹត្ត_v', 'នៅ_v-', 'ប៉ាស_n[n', 'ឌេស_n', 'ប្រីន_n]n', 'ក្រុង_n[n', 'ប៉ារីស_n]n', 'បារាំង_n', '។_.']\n",
            "['អ៊ីតាលី', 'បាន', 'ឈ្នះ', 'លើ', 'ព័រទុយហ្គាល់', '31-5', 'ក្នុង', 'ប៉ូល', 'C', 'នៃ', 'ពិធី', 'ប្រកួត', 'ពាន', 'រង្វាន់', 'ពិភព', 'លោក', 'នៃ', 'កីឡា', 'បាល់', 'ឱប', 'ឆ្នាំ', '2007', 'ដែល', 'ប្រព្រឹត្ត', 'នៅ', 'ប៉ាស', 'ឌេស', 'ប្រីន', 'ក្រុង', 'ប៉ារីស', 'បារាំង', '។']\n",
            "['n', 'v-', 'v', 'o', 'n', 'n', 'o', 'n[n', 'n]n', 'o', 'n[n', 'v]n', 'n[n', 'n]n', 'n[n', 'n]n', 'o', 'n[n', 'n', 'v]n', 'n[n', '1]n', 'n', 'v', 'v-', 'n[n', 'n', 'n]n', 'n[n', 'n]n', 'n', '.']\n",
            "[('អ', 'n'), ('៊', 'ns'), ('ី', 'ns'), ('ត', 'ns'), ('ា', 'ns'), ('ល', 'ns'), ('ី', 'ns'), ('ប', 'v-'), ('ា', 'ns'), ('ន', 'ns'), ('ឈ', 'v'), ('្', 'ns'), ('ន', 'ns'), ('ះ', 'ns'), ('ល', 'o'), ('ើ', 'ns'), ('ព', 'n'), ('័', 'ns'), ('រ', 'ns'), ('ទ', 'ns'), ('ុ', 'ns'), ('យ', 'ns'), ('ហ', 'ns'), ('្', 'ns'), ('គ', 'ns'), ('ា', 'ns'), ('ល', 'ns'), ('់', 'ns'), ('3', 'n'), ('1', 'ns'), ('-', 'ns'), ('5', 'ns'), ('ក', 'o'), ('្', 'ns'), ('ន', 'ns'), ('ុ', 'ns'), ('ង', 'ns'), ('ប', 'n'), ('៉', 'ns'), ('ូ', 'ns'), ('ល', 'ns'), ('C', 'n'), ('ន', 'o'), ('ៃ', 'ns'), ('ព', 'n'), ('ិ', 'ns'), ('ធ', 'ns'), ('ី', 'ns'), ('ប', 'v'), ('្', 'ns'), ('រ', 'ns'), ('ក', 'ns'), ('ួ', 'ns'), ('ត', 'ns'), ('ព', 'n'), ('ា', 'ns'), ('ន', 'ns'), ('រ', 'n'), ('ង', 'ns'), ('្', 'ns'), ('វ', 'ns'), ('ា', 'ns'), ('ន', 'ns'), ('់', 'ns'), ('ព', 'n'), ('ិ', 'ns'), ('ភ', 'ns'), ('ព', 'ns'), ('ល', 'n'), ('ោ', 'ns'), ('ក', 'ns'), ('ន', 'o'), ('ៃ', 'ns'), ('ក', 'n'), ('ី', 'ns'), ('ឡ', 'ns'), ('ា', 'ns'), ('ប', 'n'), ('ា', 'ns'), ('ល', 'ns'), ('់', 'ns'), ('ឱ', 'v'), ('ប', 'ns'), ('ឆ', 'n'), ('្', 'ns'), ('ន', 'ns'), ('ា', 'ns'), ('ំ', 'ns'), ('2', '1'), ('0', 'ns'), ('0', 'ns'), ('7', 'ns'), ('ដ', 'n'), ('ែ', 'ns'), ('ល', 'ns'), ('ប', 'v'), ('្', 'ns'), ('រ', 'ns'), ('ព', 'ns'), ('្', 'ns'), ('រ', 'ns'), ('ឹ', 'ns'), ('ត', 'ns'), ('្', 'ns'), ('ត', 'ns'), ('ន', 'v-'), ('ៅ', 'ns'), ('ប', 'n'), ('៉', 'ns'), ('ា', 'ns'), ('ស', 'ns'), ('ឌ', 'n'), ('េ', 'ns'), ('ស', 'ns'), ('ប', 'n'), ('្', 'ns'), ('រ', 'ns'), ('ី', 'ns'), ('ន', 'ns'), ('ក', 'n'), ('្', 'ns'), ('រ', 'ns'), ('ុ', 'ns'), ('ង', 'ns'), ('ប', 'n'), ('៉', 'ns'), ('ា', 'ns'), ('រ', 'ns'), ('ី', 'ns'), ('ស', 'ns'), ('ប', 'n'), ('ា', 'ns'), ('រ', 'ns'), ('ា', 'ns'), ('ំ', 'ns'), ('ង', 'ns'), ('។', '.')]\n"
          ]
        }
      ],
      "source": [
        "print(data[0])\n",
        "print(tok_clean[0])\n",
        "print(tag_clean[0])\n",
        "print(gen_char_with_label(tok_clean[0], tag_clean[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1yeiSkYMlzt"
      },
      "source": [
        "## Separating characters and tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "NjcJU82NMu7n"
      },
      "outputs": [],
      "source": [
        "char_labels = [gen_char_with_label(sentence, tags) for sentence, tags in zip(tok_clean, tag_clean)]\n",
        "chars_only = [[x[0] for x in sent] for sent in char_labels]\n",
        "labels_only_short = [[tags2idx[x[1]] for x in sent] for sent in char_labels]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "RjPLOYrnxYOk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "102f58fd-1a34-47b4-f986-50e1e4e5c347"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "584\n",
            "[2, 1, 1, 1, 1, 1, 1, 10, 1, 1, 3, 1, 1, 1, 5, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 5, 1, 1, 1, 1, 2, 1, 1, 1, 2, 5, 1, 2, 1, 1, 1, 3, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 5, 1, 2, 1, 1, 1, 2, 1, 1, 1, 3, 1, 2, 1, 1, 1, 1, 6, 1, 1, 1, 2, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 10, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 7]\n"
          ]
        }
      ],
      "source": [
        "leng = []\n",
        "for i in char_labels:\n",
        "  leng.append(len(i))\n",
        "print(max(leng))\n",
        "\n",
        "print(labels_only_short[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "_bmA7T1lolSb"
      },
      "outputs": [],
      "source": [
        "tag_compounds = [sentence[1] for sentence in sentence_with_compounds]\n",
        "char_labels_compounds = [gen_char_with_label(sentence[0], sentence[1]) for sentence in sentence_with_compounds]\n",
        "chars_only_compounds = [[x[0] for x in sent] for sent in char_labels_compounds]\n",
        "labels_only_compounds = [[tags2idx[x[1]] for x in sent] for sent in char_labels_compounds]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "m24MQhohM3JX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c69ab48-b9e3-442b-9b6e-c67a7f57edba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['អ៊ីតាលី', 'បាន', 'ឈ្នះ', 'លើ', 'ព័រទុយហ្គាល់', '31-5', 'ក្នុង', 'ប៉ូលC', 'នៃ', 'ពិធីប្រកួត', 'ពានរង្វាន់', 'ពិភពលោក', 'នៃ', 'កីឡាបាល់ឱប', 'ឆ្នាំ2007', 'ដែល', 'ប្រព្រឹត្ត', 'នៅ', 'ប៉ាសឌេសប្រីន', 'ក្រុងប៉ារីស', 'បារាំង', '។']\n",
            "['n', 'v-', 'v', 'o', 'n', 'n', 'o', 'cn', 'o', 'cn', 'cn', 'cn', 'o', 'cn', 'cn', 'n', 'v', 'v-', 'cn', 'cn', 'n', '.']\n",
            "[('អ', 'n'), ('៊', 'ns'), ('ី', 'ns'), ('ត', 'ns'), ('ា', 'ns'), ('ល', 'ns'), ('ី', 'ns'), ('ប', 'v-'), ('ា', 'ns'), ('ន', 'ns'), ('ឈ', 'v'), ('្', 'ns'), ('ន', 'ns'), ('ះ', 'ns'), ('ល', 'o'), ('ើ', 'ns'), ('ព', 'n'), ('័', 'ns'), ('រ', 'ns'), ('ទ', 'ns'), ('ុ', 'ns'), ('យ', 'ns'), ('ហ', 'ns'), ('្', 'ns'), ('គ', 'ns'), ('ា', 'ns'), ('ល', 'ns'), ('់', 'ns'), ('3', 'n'), ('1', 'ns'), ('-', 'ns'), ('5', 'ns'), ('ក', 'o'), ('្', 'ns'), ('ន', 'ns'), ('ុ', 'ns'), ('ង', 'ns'), ('ប', 'cn'), ('៉', 'ns'), ('ូ', 'ns'), ('ល', 'ns'), ('C', 'ns'), ('ន', 'o'), ('ៃ', 'ns'), ('ព', 'cn'), ('ិ', 'ns'), ('ធ', 'ns'), ('ី', 'ns'), ('ប', 'ns'), ('្', 'ns'), ('រ', 'ns'), ('ក', 'ns'), ('ួ', 'ns'), ('ត', 'ns'), ('ព', 'cn'), ('ា', 'ns'), ('ន', 'ns'), ('រ', 'ns'), ('ង', 'ns'), ('្', 'ns'), ('វ', 'ns'), ('ា', 'ns'), ('ន', 'ns'), ('់', 'ns'), ('ព', 'cn'), ('ិ', 'ns'), ('ភ', 'ns'), ('ព', 'ns'), ('ល', 'ns'), ('ោ', 'ns'), ('ក', 'ns'), ('ន', 'o'), ('ៃ', 'ns'), ('ក', 'cn'), ('ី', 'ns'), ('ឡ', 'ns'), ('ា', 'ns'), ('ប', 'ns'), ('ា', 'ns'), ('ល', 'ns'), ('់', 'ns'), ('ឱ', 'ns'), ('ប', 'ns'), ('ឆ', 'cn'), ('្', 'ns'), ('ន', 'ns'), ('ា', 'ns'), ('ំ', 'ns'), ('2', 'ns'), ('0', 'ns'), ('0', 'ns'), ('7', 'ns'), ('ដ', 'n'), ('ែ', 'ns'), ('ល', 'ns'), ('ប', 'v'), ('្', 'ns'), ('រ', 'ns'), ('ព', 'ns'), ('្', 'ns'), ('រ', 'ns'), ('ឹ', 'ns'), ('ត', 'ns'), ('្', 'ns'), ('ត', 'ns'), ('ន', 'v-'), ('ៅ', 'ns'), ('ប', 'cn'), ('៉', 'ns'), ('ា', 'ns'), ('ស', 'ns'), ('ឌ', 'ns'), ('េ', 'ns'), ('ស', 'ns'), ('ប', 'ns'), ('្', 'ns'), ('រ', 'ns'), ('ី', 'ns'), ('ន', 'ns'), ('ក', 'cn'), ('្', 'ns'), ('រ', 'ns'), ('ុ', 'ns'), ('ង', 'ns'), ('ប', 'ns'), ('៉', 'ns'), ('ា', 'ns'), ('រ', 'ns'), ('ី', 'ns'), ('ស', 'ns'), ('ប', 'n'), ('ា', 'ns'), ('រ', 'ns'), ('ា', 'ns'), ('ំ', 'ns'), ('ង', 'ns'), ('។', '.')]\n",
            "['អ', '៊', 'ី', 'ត', 'ា', 'ល', 'ី', 'ប', 'ា', 'ន', 'ឈ', '្', 'ន', 'ះ', 'ល', 'ើ', 'ព', '័', 'រ', 'ទ', 'ុ', 'យ', 'ហ', '្', 'គ', 'ា', 'ល', '់', '3', '1', '-', '5', 'ក', '្', 'ន', 'ុ', 'ង', 'ប', '៉', 'ូ', 'ល', 'C', 'ន', 'ៃ', 'ព', 'ិ', 'ធ', 'ី', 'ប', '្', 'រ', 'ក', 'ួ', 'ត', 'ព', 'ា', 'ន', 'រ', 'ង', '្', 'វ', 'ា', 'ន', '់', 'ព', 'ិ', 'ភ', 'ព', 'ល', 'ោ', 'ក', 'ន', 'ៃ', 'ក', 'ី', 'ឡ', 'ា', 'ប', 'ា', 'ល', '់', 'ឱ', 'ប', 'ឆ', '្', 'ន', 'ា', 'ំ', '2', '0', '0', '7', 'ដ', 'ែ', 'ល', 'ប', '្', 'រ', 'ព', '្', 'រ', 'ឹ', 'ត', '្', 'ត', 'ន', 'ៅ', 'ប', '៉', 'ា', 'ស', 'ឌ', 'េ', 'ស', 'ប', '្', 'រ', 'ី', 'ន', 'ក', '្', 'រ', 'ុ', 'ង', 'ប', '៉', 'ា', 'រ', 'ី', 'ស', 'ប', 'ា', 'រ', 'ា', 'ំ', 'ង', '។']\n",
            "137\n"
          ]
        }
      ],
      "source": [
        "print(sentence_with_compounds[0][0])\n",
        "print(sentence_with_compounds[0][1])\n",
        "print(char_labels_compounds[0])\n",
        "print(chars_only_compounds[0])\n",
        "print(len(labels_only_compounds[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVSKOByJ0QVi"
      },
      "source": [
        "## Defining compounds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCPy5JyPM8vS"
      },
      "source": [
        "## Padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "fx5MiFGNNBrz"
      },
      "outputs": [],
      "source": [
        "def pad_input(sents, seq_len, isFeature = True):\n",
        "    features = np.zeros((len(sents), seq_len),dtype=int)\n",
        "    if isFeature == False:\n",
        "        features +=-1\n",
        "    for ii, review in enumerate(sents):\n",
        "        if len(review) != 0:\n",
        "            features[ii, -len(review):] = np.array(review)[:seq_len]\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pad_mor = pad_input(labels_only_short, seq_len=300)\n",
        "# pad_com = pad_input(labels_only_compounds, seq_len=300)\n",
        "# y_labels = [[labels_mor, labels_com] for labels_mor, labels_com in zip(pad_mor,pad_com)]\n",
        "# print(y_labels[0])\n",
        "# both_labels_final = []\n",
        "# both_labels = []\n",
        "# for labels in y_labels:\n",
        "#   both_labels = [[i, j] for i, j in zip(labels[0], labels[1])]\n",
        "#   both_labels_final.append(both_labels)"
      ],
      "metadata": {
        "id": "FfEMXDCACcm4"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pad_mor = pad_input(labels_only_short, seq_len=300)\n",
        "print(pad_mor[0])\n",
        "pad_com = pad_input(labels_only_compounds, seq_len=300)\n",
        "y_labels = [[labels_mor, labels_com] for labels_mor, labels_com in zip(pad_mor,pad_com)]\n",
        "print(y_labels[3])\n",
        "both_labels_final = []\n",
        "both_labels = []\n",
        "for labels in y_labels:\n",
        "  both_labels = [[i, j] for i, j in zip(labels[0], labels[1])]\n",
        "  both_labels_final.append(both_labels)\n",
        "print(both_labels_final[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ih8ZiZYpxMX",
        "outputId": "c9a22ee3-46b7-4198-ac9d-95862f8492fc"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  1  1  1  1\n",
            "  1  1 10  1  1  3  1  1  1  5  1  2  1  1  1  1  1  1  1  1  1  1  1  2\n",
            "  1  1  1  5  1  1  1  1  2  1  1  1  2  5  1  2  1  1  1  3  1  1  1  1\n",
            "  1  2  1  1  2  1  1  1  1  1  1  2  1  1  1  2  1  1  5  1  2  1  1  1\n",
            "  2  1  1  1  3  1  2  1  1  1  1  6  1  1  1  2  1  1  3  1  1  1  1  1\n",
            "  1  1  1  1 10  1  2  1  1  1  2  1  1  2  1  1  1  1  2  1  1  1  1  2\n",
            "  1  1  1  1  1  2  1  1  1  1  1  7]\n",
            "[array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "        0,  0,  0,  0,  0,  0,  2,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
            "        1, 12,  1,  1,  3,  1,  3,  1,  5,  1,  1, 12,  1,  1,  2,  1,  1,\n",
            "        1,  1,  2,  1,  1,  1,  1,  1,  1,  1, 10,  1,  1,  3,  1,  1,  1,\n",
            "       10,  1,  1,  5,  1,  1,  1,  1,  2,  1,  1,  1,  2,  1,  6,  1,  2,\n",
            "        1,  1,  3,  1,  2,  1,  1,  1,  1,  1,  5,  1,  6,  1,  1,  4,  1,\n",
            "        1,  5,  1,  1,  1,  2,  1,  1,  9,  1,  5,  1,  1,  1,  1,  2,  1,\n",
            "        1,  3,  1,  1,  1,  1,  1, 11,  1,  1,  7]), array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "        0,  0,  0,  0,  0,  0,  2,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
            "        1, 12,  1,  1, 14,  1,  1,  1,  5,  1,  1, 12,  1,  1, 13,  1,  1,\n",
            "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 10,  1,  1,  3,  1,  1,  1,\n",
            "       10,  1,  1,  5,  1,  1,  1,  1,  2,  1,  1,  1, 13,  1,  1,  1,  2,\n",
            "        1,  1,  3,  1,  2,  1,  1,  1,  1,  1, 16,  1,  1,  1,  1,  1,  1,\n",
            "        1,  5,  1,  1,  1, 13,  1,  1,  1,  1,  5,  1,  1,  1,  1, 13,  1,\n",
            "        1,  1,  1,  1,  1,  1,  1, 11,  1,  1,  7])]\n",
            "[[0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [2, 2], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [10, 10], [1, 1], [1, 1], [3, 3], [1, 1], [1, 1], [1, 1], [5, 5], [1, 1], [2, 2], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [2, 2], [1, 1], [1, 1], [1, 1], [5, 5], [1, 1], [1, 1], [1, 1], [1, 1], [2, 13], [1, 1], [1, 1], [1, 1], [2, 1], [5, 5], [1, 1], [2, 13], [1, 1], [1, 1], [1, 1], [3, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [2, 13], [1, 1], [1, 1], [2, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [2, 13], [1, 1], [1, 1], [1, 1], [2, 1], [1, 1], [1, 1], [5, 5], [1, 1], [2, 13], [1, 1], [1, 1], [1, 1], [2, 1], [1, 1], [1, 1], [1, 1], [3, 1], [1, 1], [2, 13], [1, 1], [1, 1], [1, 1], [1, 1], [6, 1], [1, 1], [1, 1], [1, 1], [2, 2], [1, 1], [1, 1], [3, 3], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [10, 10], [1, 1], [2, 13], [1, 1], [1, 1], [1, 1], [2, 1], [1, 1], [1, 1], [2, 1], [1, 1], [1, 1], [1, 1], [1, 1], [2, 13], [1, 1], [1, 1], [1, 1], [1, 1], [2, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [2, 2], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [7, 7]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWqf_xVtwZxq"
      },
      "source": [
        "## One Hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "WtDgw2MZwYp9"
      },
      "outputs": [],
      "source": [
        "def one_hot_encode(arr, n_labels):\n",
        "    \n",
        "    arr = arr.numpy()\n",
        "\n",
        "    # Initialize the the encoded array\n",
        "    one_hot = np.zeros((arr.size, n_labels), dtype=np.float32)\n",
        "\n",
        "    # Fill the appropriate elements with ones\n",
        "    one_hot[np.arange(one_hot.shape[0]), arr.flatten()] = 1.\n",
        "\n",
        "    # Finally reshape it to get back to the original array\n",
        "    one_hot = one_hot.reshape((*arr.shape, n_labels))\n",
        "\n",
        "    return torch.from_numpy(one_hot)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0twgDWGowi-A"
      },
      "source": [
        "## Train and Test Set Split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(X_char, y_char,tags2idx,chars2idx,sentence_length=100):\n",
        "    X_train_char, X_test_char, y_train_char, y_test_char = train_test_split(X_char, y_char, test_size=0.20, random_state=1)\n",
        "\n",
        "    for i, sentence in enumerate(X_train_char):\n",
        "        # Looking up the mapping dictionary and assigning the index to the respective words\n",
        "        X_train_char[i] = [chars2idx[c] if c in chars2idx else 1 for c in sentence]\n",
        "    # for i, sentence in enumerate(y_train_char):\n",
        "    # #   # Looking up the mapping dictionary and assigning the index to the respective words\n",
        "    #     y_train_char[i] = [tags2idx[c] if c in tags2idx else 1 for c in sentence]\n",
        "    for i, sentence in enumerate(X_test_char):\n",
        "        # For test sentences, we have to tokenize the sentences as well\n",
        "        X_test_char[i] = [chars2idx[c] if c in chars2idx else 1 for c in sentence]\n",
        "    # for i, sentence in enumerate(y_test_char):\n",
        "    #   # Looking up the mapping dictionary and assigning the index to the respective words\n",
        "    #     y_test_char[i] = [tags2idx[c] if c in tags2idx else 1 for c in sentence]\n",
        "\n",
        "    X_train_char = pad_input(X_train_char,sentence_length)\n",
        "    X_test_char = pad_input(X_test_char,sentence_length)\n",
        "    # y_train_char_mor = pad_input(y_train_char[0],sentence_length,False)\n",
        "    # y_train_char_com = pad_input(y_train_char[1],sentence_length,False)\n",
        "    # y_train_char.append(y_train_char_mor)\n",
        "    # y_train_char.append(y_train_char_com)\n",
        "    # y_test_char_mor = pad_input(y_test_char[0],sentence_length,False)\n",
        "    # print(y_test_char_mor )\n",
        "    # y_test_char_com = pad_input(y_test_char[1],sentence_length,False)\n",
        "    # y_test_char.append(y_test_char_mor)\n",
        "    # y_test_char.append(y_test_char_com)\n",
        "    return X_train_char, X_test_char, y_train_char, y_test_char"
      ],
      "metadata": {
        "id": "BhGO7HYG9jUY"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(both_labels_final))"
      ],
      "metadata": {
        "id": "E5K8JGVsnSqI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47af4305-710f-42e7-becd-2d698e6d090d"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20106\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "H5jhWC3Qw1BT"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = split_data(chars_only , both_labels_final,tags2idx,chars2idx,sentence_length=300)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print((y_train[6]))\n",
        "print(len(y_train))\n",
        "print(X_train[0])"
      ],
      "metadata": {
        "id": "LB9El4nWK7nM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdbf3872-d57a-44d9-d52f-784d0b1fb10c"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [0, 0], [2, 2], [1, 1], [1, 1], [3, 3], [1, 1], [1, 1], [1, 1], [1, 1], [5, 5], [1, 1], [1, 1], [2, 13], [1, 1], [1, 1], [1, 1], [3, 1], [1, 1], [1, 1], [2, 1], [1, 1], [1, 1], [5, 5], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [3, 14], [1, 1], [1, 1], [3, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [2, 2], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [3, 3], [1, 1], [1, 1], [1, 1], [2, 13], [1, 1], [1, 1], [1, 1], [1, 1], [2, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [2, 13], [1, 1], [1, 1], [1, 1], [1, 1], [4, 1], [1, 1], [1, 1], [5, 5], [1, 1], [1, 1], [3, 3], [1, 1], [1, 1], [1, 1], [1, 1], [5, 5], [1, 1], [1, 1], [1, 1], [1, 1], [2, 13], [1, 1], [1, 1], [3, 1], [1, 1], [1, 1], [3, 1], [1, 1], [1, 1], [5, 16], [1, 1], [1, 1], [5, 1], [1, 1], [1, 1], [10, 10], [1, 1], [1, 1], [1, 1], [1, 1], [3, 3], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [5, 5], [1, 1], [1, 1], [1, 1], [1, 1], [2, 13], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [2, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [2, 2], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [2, 2], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [7, 7]]\n",
            "16084\n",
            "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  1  3 74 11 60 71 22 55 21  9 55 22 77 24 21 74\n",
            " 20 21 55  4 55 28 24 66 11 26 62 27  8 74 21 55 71 21 56  6 33 60  3 25\n",
            " 55 24 28 22 33 77  3 74 11 60 71 17 74 28 61 30 22 55 21 20 74 29 55  2\n",
            " 77  7 60 72 12 60 21 12 55 22 85  1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# POS_IDX = list((-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22))\n",
        "POS_IDX = [ i[0] for i in enumerate(POSTAGS) ]\n",
        "print(POS_IDX)\n",
        "label_one_hot_train = []\n",
        "label_one_hot_test = []\n",
        "for i in range(len(y_train)):\n",
        "  labels_array_train = np.asarray(y_train[i])\n",
        "# print(labels_array)\n",
        "  one_hot = MultiLabelBinarizer(classes = POS_IDX)\n",
        "  label_one_hot = np.array(one_hot.fit_transform(labels_array_train))\n",
        "  #label_one_hot.resize(300, len(POSTAGS))\n",
        "  label_one_hot_train.append(label_one_hot)\n",
        "for i in range(len(y_test)):\n",
        "  labels_array_test = np.asarray(y_test[i])\n",
        "# print(labels_array)\n",
        "  one_hot_1 = MultiLabelBinarizer(classes = POS_IDX)\n",
        "  label_one_hot_1 = np.array(one_hot_1.fit_transform(labels_array_test))\n",
        "  #label_one_hot_1.resize(300, len(POSTAGS))\n",
        "  label_one_hot_test.append(label_one_hot_1)\n"
      ],
      "metadata": {
        "id": "o1gTKrWpzxi2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7b725ea-1189-413d-dae9-d843f4f6c3b8"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(label_one_hot_train [0][50:80])\n",
        "print(len(label_one_hot_train))"
      ],
      "metadata": {
        "id": "Oouwuw2jWWAB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4961947-3d9b-440d-bfae-4eb3a5a4cef5"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
            "16084\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# label_one_hot_train = pad_input(label_one_hot_train, seq_len=300, isFeature = False)\n",
        "# label_one_hot_test = pad_input(label_one_hot_test, seq_len=300, isFeature = False)\n",
        "y_train_tensor = torch.tensor(label_one_hot_train)\n",
        "y_test_tensor = torch.tensor(label_one_hot_test)\n"
      ],
      "metadata": {
        "id": "fKPM9Fhy9AxJ"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SA4ux1Wwuhz"
      },
      "source": [
        "## Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "RaItWa5OwuAc"
      },
      "outputs": [],
      "source": [
        "\n",
        "# #a/ data loader\n",
        "batch_size = 128\n",
        "# create your dataset\n",
        "train_dataset = TensorDataset(torch.tensor(X_train).long(),y_train_tensor.long()) \n",
        "train_dl = torch.utils.data.DataLoader(dataset=train_dataset, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "# create your dataset\n",
        "test_dataset = TensorDataset(torch.tensor(X_test).long(),y_test_tensor.long()) \n",
        "test_dl = torch.utils.data.DataLoader(dataset=test_dataset, \n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "kLwNv5laxEvd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4a212c5-2584-42e1-c70e-992ba2d7db1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample input size:  torch.Size([128, 300])\n",
            "Sample input: \n",
            " tensor([[  0,   0,   0,  ...,  75,  55,  85],\n",
            "        [  0,   0,   0,  ...,  12,  55,  85],\n",
            "        [  0,   0,   0,  ..., 106, 115,  85],\n",
            "        ...,\n",
            "        [  0,   0,   0,  ...,  60,  22,  85],\n",
            "        [  0,   0,   0,  ...,  69,  72,  85],\n",
            "        [  0,   0,   0,  ...,  74,  27,  85]])\n",
            "\n",
            "Sample label size:  torch.Size([128, 300, 24])\n",
            "Sample label: \n",
            " tensor([[[1, 0, 0,  ..., 0, 0, 0],\n",
            "         [1, 0, 0,  ..., 0, 0, 0],\n",
            "         [1, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 1, 0,  ..., 0, 0, 0],\n",
            "         [0, 1, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0]],\n",
            "\n",
            "        [[1, 0, 0,  ..., 0, 0, 0],\n",
            "         [1, 0, 0,  ..., 0, 0, 0],\n",
            "         [1, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 1, 0,  ..., 0, 0, 0],\n",
            "         [0, 1, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0]],\n",
            "\n",
            "        [[1, 0, 0,  ..., 0, 0, 0],\n",
            "         [1, 0, 0,  ..., 0, 0, 0],\n",
            "         [1, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 1, 0,  ..., 0, 0, 0],\n",
            "         [0, 1, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[1, 0, 0,  ..., 0, 0, 0],\n",
            "         [1, 0, 0,  ..., 0, 0, 0],\n",
            "         [1, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 1, 0,  ..., 0, 0, 0],\n",
            "         [0, 1, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0]],\n",
            "\n",
            "        [[1, 0, 0,  ..., 0, 0, 0],\n",
            "         [1, 0, 0,  ..., 0, 0, 0],\n",
            "         [1, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 1, 0,  ..., 0, 0, 0],\n",
            "         [0, 1, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0]],\n",
            "\n",
            "        [[1, 0, 0,  ..., 0, 0, 0],\n",
            "         [1, 0, 0,  ..., 0, 0, 0],\n",
            "         [1, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 1, 0,  ..., 0, 0, 0],\n",
            "         [0, 1, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0]]])\n"
          ]
        }
      ],
      "source": [
        "# obtain one batch of training data\n",
        "dataiter = iter(train_dl)\n",
        "sample_x, sample_y = dataiter.next()\n",
        "\n",
        "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
        "print('Sample input: \\n', sample_x)\n",
        "print()\n",
        "print('Sample label size: ', sample_y.size()) # batch_size\n",
        "print('Sample label: \\n', sample_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "KIvpGK76EbLX"
      },
      "outputs": [],
      "source": [
        "cc = one_hot_encode(torch.tensor([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
        "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
        "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
        "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
        "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
        "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
        "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
        "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
        "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
        "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
        "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
        "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
        "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
        "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
        "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
        "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
        "          0,   0,   0,   0,   0,   0,   0,   0,   0,   1,  30,  56,   9,  56,\n",
        "         22,  75,  28,  36,  22,  78,  20,  26,  75,  26,  17,  56,   9,  56,\n",
        "         20,  61,   6, 163, 158, 161,  12,  68,  29,  26,  56,  21,  19,  72,\n",
        "         34,  72, 108, 115, 125, 130, 119, 124, 121, 135,  19,  19,  59,   6,\n",
        "         22,  75,  28,  34,  68,  29,  26,  63,  27, 122, 131, 131, 136,   2,\n",
        "         21,  75,  29,  73,  86,   1]), len(CHARS))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cc[0:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNxfqUMCZgqr",
        "outputId": "343b610a-2c66-4c31-ec32-a6a22d0c050e"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [1., 0., 0.,  ..., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cc = one_hot_encode(torch.tensor([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
        "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
        "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
        "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
        "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
        "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
        "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
        "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
        "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
        "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
        "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
        "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
        "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
        "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
        "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
        "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
        "          0,   0,   0,   0,   0,   0,   0,   0,   0,   1,  30,  56,   9,  56,\n",
        "         22,  75,  28,  36,  22,  78,  20,  26,  75,  26,  17,  56,   9,  56,\n",
        "         20,  61,   6, 163, 158, 161,  12,  68,  29,  26,  56,  21,  19,  72,\n",
        "         34,  72, 108, 115, 125, 130, 119, 124, 121, 135,  19,  19,  59,   6,\n",
        "         22,  75,  28,  34,  68,  29,  26,  63,  27, 122, 131, 131, 136,   2,\n",
        "         21,  75,  29,  73,  86,   1]), len(CHARS))"
      ],
      "metadata": {
        "id": "MR3Fh-JL_BUX"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Zo7gh0iUTH4b"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cc)"
      ],
      "metadata": {
        "id": "T-huwiF0TIAr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90356c2b-6189-429f-ba34-913dbb37ce0e"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example = [ 30,  56]\n",
        "example_one_hot = one_hot_encode(torch.tensor([ -1,  -1]), len(POSTAGS))\n",
        "for i in example:\n",
        "  print(idx2chars[i])\n",
        "example_one_hot[0]"
      ],
      "metadata": {
        "id": "J7F5bdEQYWu0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b46c976-bb29-44cd-cac3-365990d9e0c1"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "វ\n",
            "ិ\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "y1l2iirAF7fj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5b9bd13-b557-4cfe-c9f4-0aef693620aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.]])\n"
          ]
        }
      ],
      "source": [
        "print(cc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "Iy2HY2wgGg8D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3da3354e-c712-4145-d10a-28bcac09a46e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "168\n"
          ]
        }
      ],
      "source": [
        "print(len(CHARS))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLvk6urbxEZ-"
      },
      "source": [
        "# LSTM Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "WD3_jSW_xVFi"
      },
      "outputs": [],
      "source": [
        "\n",
        "class WordSegment(nn.Module):\n",
        "    \n",
        "    def __init__(self, n_input, n_output, n_hidden=100, n_layers=2,\n",
        "                               drop_prob=0.5): \n",
        "        super().__init__()\n",
        "        self.drop_prob = drop_prob\n",
        "        self.n_layers = n_layers\n",
        "        self.n_hidden = n_hidden\n",
        "        \n",
        "\n",
        "        \n",
        "        ## TODO: define the LSTM\n",
        "        self.lstm = nn.LSTM(n_input, n_hidden, n_layers, \n",
        "                            dropout=drop_prob, batch_first=True)\n",
        "        \n",
        "        ## TODO: define a dropout layer\n",
        "        self.dropout = nn.Dropout(drop_prob)\n",
        "        \n",
        "        ## TODO: define the final, fully-connected output layer\n",
        "        self.fc = nn.Linear(n_hidden, n_output)\n",
        "        #self.sig = nn.Sigmoid()\n",
        "      \n",
        "    \n",
        "    def forward(self, x, hidden):\n",
        "        ''' Forward pass through the network. \n",
        "            These inputs are x, and the hidden/cell state `hidden`. '''\n",
        "                \n",
        "        ## TODO: Get the outputs and the new hidden state from the lstm\n",
        "        r_output, hidden = self.lstm(x, hidden)\n",
        "        \n",
        "        ## TODO: pass through a dropout layer\n",
        "        out = self.dropout(r_output)\n",
        "        \n",
        "        # Stack up LSTM outputs using view\n",
        "        # you may need to use contiguous to reshape the output\n",
        "        out = out.contiguous().view(-1, self.n_hidden)\n",
        "        \n",
        "        ## TODO: put x through the fully-connected layer\n",
        "        out = self.fc(out)\n",
        "        #sig_out = self.sig(out)\n",
        "        \n",
        "        \n",
        "        # return the final output and the hidden state\n",
        "        return out, hidden\n",
        "    \n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        ''' Initializes hidden state '''\n",
        "        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "        \n",
        "        if (train_on_gpu):\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n",
        "                  weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
        "        else:\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n",
        "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n",
        "        \n",
        "        return hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naDLRfqjxbLW"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def time_since(since):\n",
        "    s = time.time() - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)"
      ],
      "metadata": {
        "id": "iOvL9BmoL8p7"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_losses = []\n",
        "losses = []\n",
        "losses_final=[]\n",
        "val_losses_final = []\n",
        "valid_accuracy = []\n",
        "training_accuracy = []\n",
        "def train(net, train_dl,test_dl,seq_length=300, epochs=100, lr=0.001, clip=5, print_every=100):\n",
        "    ''' Training a network \n",
        "    \n",
        "        Arguments\n",
        "        ---------\n",
        "        \n",
        "        net: CharRNN network\n",
        "        data: text data to train the network\n",
        "        epochs: Number of epochs to train\n",
        "        batch_size: Number of mini-sequences per mini-batch, aka batch size\n",
        "        seq_length: Number of character steps per mini-batch\n",
        "        lr: learning rate\n",
        "        clip: gradient clipping\n",
        "        val_frac: Fraction of data to hold out for validation\n",
        "        print_every: Number of steps for printing training and validation loss\n",
        "    \n",
        "    '''\n",
        "    correct = 0.\n",
        "    total = 0.\n",
        "    train_correct = 0.\n",
        "    train_total = 0.\n",
        "    net.train()\n",
        "    start = time.time()\n",
        "    opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "    # criterion = nn.CrossEntropyLoss(ignore_index = -1)\n",
        "    #weight = torch.rand(23).cuda()\n",
        "    #pos_weight = torch.tensor([1,1, 1, 1, 1, 1, 1,1, 1, 1, 1 ,1 ,1 ,1, 1, 1, 1, 1, 1, 1, 1, 1, 1]).cuda()\n",
        "    criterion = nn.BCELoss()\n",
        "    \n",
        "    if(train_on_gpu):\n",
        "        net.cuda()\n",
        "    \n",
        "    counter = 0\n",
        "    #n_chars = len(net.chars)\n",
        "    for e in range(epochs):\n",
        "\n",
        "        \n",
        "        for x, y in train_dl:\n",
        "                    # initialize hidden state\n",
        "            batch_size = x.shape[0]\n",
        "            h = net.init_hidden(batch_size)\n",
        "            counter += 1\n",
        "            #print(x)\n",
        "            # One-hot encode our data and make them Torch tensors\n",
        "            x = one_hot_encode(x, len(CHARS))\n",
        "            inputs, targets = x, y\n",
        "            if(train_on_gpu):\n",
        "                inputs, targets= inputs.cuda(), targets.cuda()\n",
        "\n",
        "            # Creating new variables for the hidden state, otherwise\n",
        "            # we'd backprop through the entire training history\n",
        "            h = tuple([each.data for each in h])\n",
        "\n",
        "            # zero accumulated gradients\n",
        "            net.zero_grad()\n",
        "            \n",
        "            # get the output from the model\n",
        "            output, h = net(inputs, h)\n",
        "            # # calculate the loss and perform backprop\n",
        "            output = torch.sigmoid(output)\n",
        "            predicted = torch.round(output)\n",
        "            loss = criterion(output, targets.view(batch_size*seq_length,len(POSTAGS)).float())\n",
        "            loss.backward()\n",
        "            losses.append(loss.item())\n",
        "            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "            train_total += targets.view(batch_size*seq_length,len(POSTAGS)).float().size(0)*len(POSTAGS)\n",
        "            #calculate how many images were correctly classified\n",
        "            train_correct += (predicted == targets.view(batch_size*seq_length,len(POSTAGS)).float()).sum().item()\n",
        "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "            opt.step() \n",
        "            # loss stats\n",
        "            if counter % print_every == 0:\n",
        "                # Get validation loss\n",
        "                net.eval()\n",
        "                for x, y in test_dl:\n",
        "                    batch_size = x.shape[0]\n",
        "                    val_h = net.init_hidden(batch_size)\n",
        "                    # One-hot encode our data and make them Torch tensors\n",
        "                    x = one_hot_encode(x, len(CHARS))\n",
        "                    inputs, targets = x, y\n",
        "                    # Creating new variables for the hidden state, otherwise\n",
        "                    # we'd backprop through the entire training history\n",
        "                    val_h = tuple([each.data for each in val_h])\n",
        "                    \n",
        "                    inputs, targets = x, y\n",
        "                    if(train_on_gpu):\n",
        "                        inputs, targets = inputs.cuda(), targets.cuda()\n",
        "\n",
        "                    output, val_h = net(inputs, val_h)\n",
        "                    output = torch.sigmoid(output)\n",
        "                    predicted = torch.round(output)\n",
        "                    val_loss = criterion(output, targets.view(batch_size*seq_length,len(POSTAGS)).float())\n",
        "                    #print(targets.view(batch_size*seq_length).shape)\n",
        "                    val_losses.append(val_loss.item())\n",
        "                    #accuracy_list.append(acc.item())\n",
        "                    total += targets.view(batch_size*seq_length,len(POSTAGS)).float().size(0)*len(POSTAGS)\n",
        "                     #calculate how many images were correctly classified\n",
        "                    correct += (predicted == targets.view(batch_size*seq_length,len(POSTAGS)).float()).sum().item()\n",
        "                #     print(\"predicted == targets.view(batch_size*seq_length,len(POSTAGS)).float()\", (predicted == targets.view(batch_size*seq_length,len(POSTAGS)).float()).sum())\n",
        "                #     print(\"predicted\", predicted.size(0))\n",
        "                #     print(\"targets\" , targets.view(batch_size*seq_length,len(POSTAGS)).float().size())\n",
        "                accuracy = 100 * correct / total\n",
        "                valid_accuracy.append(accuracy)\n",
        "                print(\"valid correction\", correct)\n",
        "                train_accuracy = 100 * train_correct / train_total\n",
        "                training_accuracy.append(train_accuracy) \n",
        "                print(\"train correction\", train_correct)\n",
        "                net.train() # reset to train mode after iterationg through validation data\n",
        "                losses_final.append(np.mean(losses))\n",
        "                val_losses_final.append(np.mean(val_losses))\n",
        "\n",
        "                print(\"Time: {}...\".format(time_since(start)),\n",
        "                      \"Epoch: {}/{}...\".format(e+1, epochs),\n",
        "                      \"Step: {}...\".format(counter),\n",
        "                      \"loss: {:.4f}...\".format(loss.item()),\n",
        "                      \"Val loss: {:.4f}\".format(np.mean(val_losses)),\n",
        "                      \"Train Accuracy: {}%\".format(train_accuracy), \n",
        "                      \"Val Accuracy: {}%\".format(accuracy))\n",
        "                #\"Accuracy: {:.4f}\".format(np.mean(accuracy_list)),"
      ],
      "metadata": {
        "id": "wfyeSRAZmaYK"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# m = nn.Sigmoid()\n",
        "# loss = nn.BCELoss()\n",
        "# input = torch.randn(3, requires_grad=True)\n",
        "# target = torch.empty(3).random_(2)\n",
        "# output = loss(m(input), target)\n",
        "# output.backward()\n",
        "# print(input)\n",
        "# print(target)\n",
        "# print(output)\n"
      ],
      "metadata": {
        "id": "u_d157MHNUMP"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre = torch.tensor([0, 1, 0, 0, 0, 1])\n",
        "tar = torch.tensor([0, 1, 1, 0, 1, 1])\n",
        "cor = ((pre==tar).sum().item())\n",
        "print(cor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCz712l8sx2-",
        "outputId": "e9229ccf-a6fd-4e23-cf83-2710ba83cf26"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "DWFeBA6UxjC8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2286313-f1d2-4104-fdd6-23aea25af4d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WordSegment(\n",
            "  (lstm): LSTM(168, 1024, num_layers=4, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=1024, out_features=24, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "net = WordSegment(len(CHARS),len(POSTAGS), n_layers = 4,n_hidden=512,drop_prob=0.5 ) #3 #512\n",
        "# netRNN = WordSegment(len(CHARS),11, n_layers = 4)\n",
        "print(net)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "Mt-C7bXOxthu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bae1281e-f986-475f-aded-beeb2d7dce63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valid correction 27774942.0\n",
            "train correction 88987724.0\n",
            "Time: 1m 52s... Epoch: 1/200... Step: 100... loss: 0.0827... Val loss: 0.0843 Train Accuracy: 96.55786024305556% Val Accuracy: 95.91324796950107%\n",
            "valid correction 55551832.0\n",
            "train correction 177706359.0\n",
            "Time: 3m 43s... Epoch: 2/200... Step: 200... loss: 0.0815... Val loss: 0.0841 Train Accuracy: 96.57786331976835% Val Accuracy: 95.9166114149953%\n",
            "valid correction 83333678.0\n",
            "train correction 266482358.0\n",
            "Time: 5m 35s... Epoch: 3/200... Step: 300... loss: 0.0823... Val loss: 0.0839 Train Accuracy: 96.60534195842324% Val Accuracy: 95.92343729856161%\n",
            "valid correction 111120923.0\n",
            "train correction 355245144.0\n",
            "Time: 7m 27s... Epoch: 4/200... Step: 400... loss: 0.0809... Val loss: 0.0837 Train Accuracy: 96.61549959531082% Val Accuracy: 95.93151123680866%\n",
            "valid correction 138911216.0\n",
            "train correction 444373494.0\n",
            "Time: 9m 20s... Epoch: 4/200... Step: 500... loss: 0.0816... Val loss: 0.0835 Train Accuracy: 96.63452876766665% Val Accuracy: 95.93846068843582%\n",
            "valid correction 166787021.0\n",
            "train correction 533336965.0\n",
            "Time: 11m 12s... Epoch: 5/200... Step: 600... loss: 0.0781... Val loss: 0.0831 Train Accuracy: 96.67281592219437% Val Accuracy: 95.99230908245391%\n",
            "valid correction 194876771.0\n",
            "train correction 622553273.0\n",
            "Time: 13m 4s... Epoch: 6/200... Step: 700... loss: 0.0731... Val loss: 0.0823 Train Accuracy: 96.73946337112454% Val Accuracy: 96.13631524630406%\n",
            "valid correction 223278032.0\n",
            "train correction 712229160.0\n",
            "Time: 14m 56s... Epoch: 7/200... Step: 800... loss: 0.0651... Val loss: 0.0810 Train Accuracy: 96.8519588261403% Val Accuracy: 96.37878473948837%\n",
            "valid correction 251706668.0\n",
            "train correction 802497280.0\n",
            "Time: 16m 48s... Epoch: 8/200... Step: 900... loss: 0.0598... Val loss: 0.0797 Train Accuracy: 97.01106739856174% Val Accuracy: 96.57787569601759%\n",
            "valid correction 280305117.0\n",
            "train correction 893344578.0\n",
            "Time: 18m 40s... Epoch: 8/200... Step: 1000... loss: 0.0527... Val loss: 0.0779 Train Accuracy: 97.16790075598576% Val Accuracy: 96.7957887866733%\n",
            "valid correction 308932678.0\n",
            "train correction 984056372.0\n",
            "Time: 20m 32s... Epoch: 9/200... Step: 1100... loss: 0.0478... Val loss: 0.0762 Train Accuracy: 97.31323771866535% Val Accuracy: 96.98322044412298%\n",
            "valid correction 337567484.0\n",
            "train correction 1074846102.0\n",
            "Time: 22m 24s... Epoch: 10/200... Step: 1200... loss: 0.0486... Val loss: 0.0745 Train Accuracy: 97.44143810431407% Val Accuracy: 97.1414983792843%\n",
            "valid correction 366212145.0\n",
            "train correction 1165670095.0\n",
            "Time: 24m 16s... Epoch: 11/200... Step: 1300... loss: 0.0475... Val loss: 0.0729 Train Accuracy: 97.55279844875606% Val Accuracy: 97.27804367644622%\n",
            "valid correction 394863445.0\n",
            "train correction 1256527209.0\n",
            "Time: 26m 8s... Epoch: 12/200... Step: 1400... loss: 0.0456... Val loss: 0.0714 Train Accuracy: 97.65083591657528% Val Accuracy: 97.39672007332686%\n",
            "valid correction 423522474.0\n",
            "train correction 1347708152.0\n",
            "Time: 28m 1s... Epoch: 12/200... Step: 1500... loss: 0.0438... Val loss: 0.0700 Train Accuracy: 97.73684067011517% Val Accuracy: 97.5013522846566%\n",
            "valid correction 452140699.0\n",
            "train correction 1438522906.0\n",
            "Time: 29m 53s... Epoch: 13/200... Step: 1600... loss: 0.0474... Val loss: 0.0689 Train Accuracy: 97.8082400209307% Val Accuracy: 97.58409887113929%\n",
            "valid correction 480800580.0\n",
            "train correction 1529407145.0\n",
            "Time: 31m 45s... Epoch: 14/200... Step: 1700... loss: 0.0388... Val loss: 0.0676 Train Accuracy: 97.87569301093765% Val Accuracy: 97.66557219605893%\n",
            "valid correction 509462629.0\n",
            "train correction 1620305983.0\n",
            "Time: 33m 37s... Epoch: 15/200... Step: 1800... loss: 0.0422... Val loss: 0.0664 Train Accuracy: 97.9365393756262% Val Accuracy: 97.73840885162471%\n",
            "valid correction 538124040.0\n",
            "train correction 1711212119.0\n",
            "Time: 35m 29s... Epoch: 16/200... Step: 1900... loss: 0.0416... Val loss: 0.0654 Train Accuracy: 97.99140342257405% Val Accuracy: 97.80346253500484%\n",
            "valid correction 566788049.0\n",
            "train correction 1802432123.0\n",
            "Time: 37m 21s... Epoch: 16/200... Step: 2000... loss: 0.0399... Val loss: 0.0644 Train Accuracy: 98.0409629752922% Val Accuracy: 97.86245942455385%\n",
            "valid correction 595452728.0\n",
            "train correction 1893348005.0\n",
            "Time: 39m 13s... Epoch: 17/200... Step: 2100... loss: 0.0407... Val loss: 0.0634 Train Accuracy: 98.08613358440427% Val Accuracy: 97.91594773718096%\n",
            "valid correction 624117878.0\n",
            "train correction 1984263666.0\n",
            "Time: 41m 5s... Epoch: 18/200... Step: 2200... loss: 0.0402... Val loss: 0.0625 Train Accuracy: 98.12719006214424% Val Accuracy: 97.96464740643631%\n",
            "valid correction 652785595.0\n",
            "train correction 2075187721.0\n",
            "Time: 42m 57s... Epoch: 19/200... Step: 2300... loss: 0.0366... Val loss: 0.0617 Train Accuracy: 98.16507615785522% Val Accuracy: 98.00949773227923%\n",
            "valid correction 681454925.0\n",
            "train correction 2166111217.0\n",
            "Time: 44m 49s... Epoch: 20/200... Step: 2400... loss: 0.0382... Val loss: 0.0609 Train Accuracy: 98.19978200405038% Val Accuracy: 98.0508426167652%\n",
            "valid correction 710124564.0\n",
            "train correction 2257350443.0\n",
            "Time: 46m 41s... Epoch: 20/200... Step: 2500... loss: 0.0373... Val loss: 0.0601 Train Accuracy: 98.2319105103054% Val Accuracy: 98.08892259240842%\n",
            "valid correction 738791968.0\n",
            "train correction 2348278430.0\n",
            "Time: 48m 33s... Epoch: 21/200... Step: 2600... loss: 0.0401... Val loss: 0.0595 Train Accuracy: 98.26156361305267% Val Accuracy: 98.12377649423895%\n",
            "valid correction 767463363.0\n",
            "train correction 2439211993.0\n",
            "Time: 50m 25s... Epoch: 22/200... Step: 2700... loss: 0.0379... Val loss: 0.0588 Train Accuracy: 98.2892465597321% Val Accuracy: 98.15655906403668%\n",
            "valid correction 796134665.0\n",
            "train correction 2530149773.0\n",
            "Time: 52m 17s... Epoch: 23/200... Step: 2800... loss: 0.0364... Val loss: 0.0581 Train Accuracy: 98.31511747533641% Val Accuracy: 98.18698855205102%\n",
            "valid correction 824805769.0\n",
            "train correction 2621083193.0\n",
            "Time: 54m 9s... Epoch: 24/200... Step: 2900... loss: 0.0411... Val loss: 0.0576 Train Accuracy: 98.33904188172257% Val Accuracy: 98.21529587746322%\n",
            "valid correction 853479461.0\n",
            "train correction 2712339327.0\n",
            "Time: 56m 2s... Epoch: 24/200... Step: 3000... loss: 0.0382... Val loss: 0.0570 Train Accuracy: 98.36177515135374% Val Accuracy: 98.24201394644271%\n",
            "valid correction 882154501.0\n",
            "train correction 2803283386.0\n",
            "Time: 57m 54s... Epoch: 25/200... Step: 3100... loss: 0.0390... Val loss: 0.0564 Train Accuracy: 98.3830240565169% Val Accuracy: 98.2671584288207%\n",
            "valid correction 910829151.0\n",
            "train correction 2894233392.0\n",
            "Time: 59m 46s... Epoch: 26/200... Step: 3200... loss: 0.0363... Val loss: 0.0559 Train Accuracy: 98.40314810281518% Val Accuracy: 98.290689294816%\n",
            "valid correction 939505054.0\n",
            "train correction 2985178946.0\n",
            "Time: 61m 38s... Epoch: 27/200... Step: 3300... loss: 0.0382... Val loss: 0.0554 Train Accuracy: 98.42190661840887% Val Accuracy: 98.31292516579687%\n",
            "valid correction 968181661.0\n",
            "train correction 3076443854.0\n",
            "Time: 63m 30s... Epoch: 27/200... Step: 3400... loss: 0.0361... Val loss: 0.0549 Train Accuracy: 98.43980237829015% Val Accuracy: 98.33392454653003%\n",
            "valid correction 996858234.0\n",
            "train correction 3167391641.0\n",
            "Time: 65m 22s... Epoch: 28/200... Step: 3500... loss: 0.0349... Val loss: 0.0545 Train Accuracy: 98.45651094743303% Val Accuracy: 98.3537206080841%\n",
            "valid correction 1025535489.0\n",
            "train correction 3258350666.0\n",
            "Time: 67m 14s... Epoch: 29/200... Step: 3600... loss: 0.0369... Val loss: 0.0540 Train Accuracy: 98.4726316042699% Val Accuracy: 98.3724823079544%\n",
            "valid correction 1054213334.0\n",
            "train correction 3349309829.0\n",
            "Time: 69m 6s... Epoch: 30/200... Step: 3700... loss: 0.0356... Val loss: 0.0536 Train Accuracy: 98.4878855816017% Val Accuracy: 98.39028492689607%\n",
            "valid correction 1082891887.0\n",
            "train correction 3440266706.0\n",
            "Time: 70m 58s... Epoch: 31/200... Step: 3800... loss: 0.0371... Val loss: 0.0532 Train Accuracy: 98.5022718474845% Val Accuracy: 98.40721490501075%\n",
            "valid correction 1111570565.0\n",
            "train correction 3531500267.0\n",
            "Time: 72m 51s... Epoch: 31/200... Step: 3900... loss: 0.0387... Val loss: 0.0528 Train Accuracy: 98.51493295461647% Val Accuracy: 98.42328774716269%\n",
            "valid correction 1140250949.0\n",
            "train correction 3622460598.0\n",
            "Time: 74m 43s... Epoch: 32/200... Step: 4000... loss: 0.0364... Val loss: 0.0525 Train Accuracy: 98.52801751149546% Val Accuracy: 98.43870422744351%\n",
            "valid correction 1168931401.0\n",
            "train correction 3713422435.0\n",
            "Time: 76m 35s... Epoch: 33/200... Step: 4100... loss: 0.0373... Val loss: 0.0521 Train Accuracy: 98.54050424389793% Val Accuracy: 98.45337441160339%\n",
            "valid correction 1197612030.0\n",
            "train correction 3804383383.0\n",
            "Time: 78m 27s... Epoch: 34/200... Step: 4200... loss: 0.0385... Val loss: 0.0518 Train Accuracy: 98.55237377966947% Val Accuracy: 98.46736056846076%\n",
            "valid correction 1226292778.0\n",
            "train correction 3895347506.0\n",
            "Time: 80m 19s... Epoch: 35/200... Step: 4300... loss: 0.0370... Val loss: 0.0514 Train Accuracy: 98.563771979152% Val Accuracy: 98.48070576300631%\n",
            "valid correction 1254973689.0\n",
            "train correction 3986627085.0\n",
            "Time: 82m 11s... Epoch: 35/200... Step: 4400... loss: 0.0370... Val loss: 0.0511 Train Accuracy: 98.57473086358651% Val Accuracy: 98.49345715044528%\n",
            "valid correction 1283654914.0\n",
            "train correction 4077594867.0\n",
            "Time: 84m 3s... Epoch: 36/200... Step: 4500... loss: 0.0354... Val loss: 0.0508 Train Accuracy: 98.58521401257993% Val Accuracy: 98.50566590542142%\n",
            "valid correction 1312336385.0\n",
            "train correction 4168558122.0\n",
            "Time: 85m 55s... Epoch: 37/200... Step: 4600... loss: 0.0368... Val loss: 0.0505 Train Accuracy: 98.59513464097255% Val Accuracy: 98.5173623122344%\n",
            "valid correction 1341017916.0\n",
            "train correction 4259527809.0\n",
            "Time: 87m 48s... Epoch: 38/200... Step: 4700... loss: 0.0363... Val loss: 0.0502 Train Accuracy: 98.60478232039718% Val Accuracy: 98.52856540798658%\n",
            "valid correction 1369700701.0\n",
            "train correction 4350491644.0\n",
            "Time: 89m 40s... Epoch: 39/200... Step: 4800... loss: 0.0365... Val loss: 0.0499 Train Accuracy: 98.61389565281097% Val Accuracy: 98.53939192370204%\n",
            "valid correction 1398384006.0\n",
            "train correction 4441774312.0\n",
            "Time: 91m 32s... Epoch: 39/200... Step: 4900... loss: 0.0375... Val loss: 0.0496 Train Accuracy: 98.62277929827104% Val Accuracy: 98.54981318733361%\n",
            "valid correction 1427067579.0\n",
            "train correction 4532743249.0\n",
            "Time: 93m 24s... Epoch: 40/200... Step: 5000... loss: 0.0358... Val loss: 0.0494 Train Accuracy: 98.63127909711386% Val Accuracy: 98.55983610972982%\n",
            "valid correction 1455751642.0\n",
            "train correction 4623708465.0\n",
            "Time: 95m 16s... Epoch: 41/200... Step: 5100... loss: 0.0356... Val loss: 0.0491 Train Accuracy: 98.63936643677808% Val Accuracy: 98.56949915443275%\n",
            "valid correction 1484435814.0\n",
            "train correction 4714681054.0\n",
            "Time: 97m 8s... Epoch: 42/200... Step: 5200... loss: 0.0355... Val loss: 0.0489 Train Accuracy: 98.64729722016335% Val Accuracy: 98.57879778207041%\n",
            "valid correction 1513120363.0\n",
            "train correction 4805647780.0\n",
            "Time: 99m 0s... Epoch: 43/200... Step: 5300... loss: 0.0344... Val loss: 0.0486 Train Accuracy: 98.65480858168412% Val Accuracy: 98.58777008163695%\n",
            "valid correction 1541804975.0\n",
            "train correction 4896932547.0\n",
            "Time: 100m 52s... Epoch: 43/200... Step: 5400... loss: 0.0320... Val loss: 0.0484 Train Accuracy: 98.66215234258647% Val Accuracy: 98.59641410257984%\n",
            "valid correction 1570489668.0\n",
            "train correction 4987901816.0\n",
            "Time: 102m 44s... Epoch: 44/200... Step: 5500... loss: 0.0356... Val loss: 0.0482 Train Accuracy: 98.66917071321095% Val Accuracy: 98.60474888115365%\n",
            "valid correction 1599174101.0\n",
            "train correction 5078873491.0\n",
            "Time: 104m 36s... Epoch: 45/200... Step: 5600... loss: 0.0336... Val loss: 0.0480 Train Accuracy: 98.67598535836498% Val Accuracy: 98.61276995621306%\n",
            "valid correction 1627858700.0\n",
            "train correction 5169838915.0\n",
            "Time: 106m 28s... Epoch: 46/200... Step: 5700... loss: 0.0372... Val loss: 0.0477 Train Accuracy: 98.68244174691307% Val Accuracy: 98.62051964681581%\n",
            "valid correction 1656542914.0\n",
            "train correction 5260811151.0\n",
            "Time: 108m 21s... Epoch: 47/200... Step: 5800... loss: 0.0357... Val loss: 0.0475 Train Accuracy: 98.68880344806783% Val Accuracy: 98.62797918440913%\n",
            "valid correction 1685227297.0\n",
            "train correction 5352094033.0\n",
            "Time: 110m 13s... Epoch: 47/200... Step: 5900... loss: 0.0356... Val loss: 0.0473 Train Accuracy: 98.69491240722252% Val Accuracy: 98.63519574777519%\n",
            "valid correction 1713911020.0\n",
            "train correction 5443066346.0\n",
            "Time: 112m 5s... Epoch: 48/200... Step: 6000... loss: 0.0360... Val loss: 0.0471 Train Accuracy: 98.7008555517258% Val Accuracy: 98.64213377350498%\n",
            "valid correction 1742593808.0\n",
            "train correction 5534038249.0\n",
            "Time: 113m 57s... Epoch: 49/200... Step: 6100... loss: 0.0324... Val loss: 0.0470 Train Accuracy: 98.70659666929787% Val Accuracy: 98.64879139233307%\n",
            "valid correction 1771275851.0\n",
            "train correction 5625004721.0\n",
            "Time: 115m 49s... Epoch: 50/200... Step: 6200... loss: 0.0334... Val loss: 0.0468 Train Accuracy: 98.71205741586827% Val Accuracy: 98.65519275481269%\n",
            "valid correction 1799957955.0\n",
            "train correction 5715975752.0\n",
            "Time: 117m 41s... Epoch: 50/200... Step: 6300... loss: 0.0349... Val loss: 0.0466 Train Accuracy: 98.71742366464947% Val Accuracy: 98.66139424303894%\n",
            "valid correction 1828639730.0\n",
            "train correction 5807256697.0\n",
            "Time: 119m 33s... Epoch: 51/200... Step: 6400... loss: 0.0336... Val loss: 0.0464 Train Accuracy: 98.72257406840745% Val Accuracy: 98.66738418300044%\n",
            "valid correction 1857321242.0\n",
            "train correction 5898231484.0\n",
            "Time: 121m 25s... Epoch: 52/200... Step: 6500... loss: 0.0335... Val loss: 0.0462 Train Accuracy: 98.72767623520917% Val Accuracy: 98.67317584481931%\n",
            "valid correction 1886002647.0\n",
            "train correction 5989199871.0\n",
            "Time: 123m 17s... Epoch: 53/200... Step: 6600... loss: 0.0353... Val loss: 0.0461 Train Accuracy: 98.73251839934228% Val Accuracy: 98.6787864033171%\n",
            "valid correction 1914684034.0\n",
            "train correction 6080174034.0\n",
            "Time: 125m 9s... Epoch: 54/200... Step: 6700... loss: 0.0339... Val loss: 0.0459 Train Accuracy: 98.73730992312741% Val Accuracy: 98.68422855472348%\n",
            "valid correction 1943365452.0\n",
            "train correction 6171456547.0\n",
            "Time: 127m 2s... Epoch: 54/200... Step: 6800... loss: 0.0353... Val loss: 0.0458 Train Accuracy: 98.7418891882766% Val Accuracy: 98.68951221711957%\n",
            "valid correction 1972046691.0\n",
            "train correction 6262426974.0\n",
            "Time: 128m 54s... Epoch: 55/200... Step: 6900... loss: 0.0358... Val loss: 0.0456 Train Accuracy: 98.74634707576844% Val Accuracy: 98.6946337715031%\n",
            "valid correction 2000727862.0\n",
            "train correction 6353401187.0\n",
            "Time: 130m 46s... Epoch: 56/200... Step: 7000... loss: 0.0335... Val loss: 0.0455 Train Accuracy: 98.75073653481253% Val Accuracy: 98.69960564119565%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-108-8363d6bb1209>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-96-b922505c8ea1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, train_dl, test_dl, seq_length, epochs, lr, clip, print_every)\u001b[0m\n\u001b[1;32m     98\u001b[0m                     \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPOSTAGS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                     \u001b[0;31m#print(targets.view(batch_size*seq_length).shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                     \u001b[0mval_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m                     \u001b[0;31m#accuracy_list.append(acc.item())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                     \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPOSTAGS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPOSTAGS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train(net,train_dl,test_dl, epochs=200, lr=0.0001, clip=5, print_every=100)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pickle.dump(net, open(\"model_gb.pkl\", \"wb\"))"
      ],
      "metadata": {
        "id": "YNM4YCOQ2eXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(losses_final,'-o')\n",
        "plt.plot(val_losses_final,'-o')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['Train','Valid'])\n",
        "plt.title('Train vs Valid Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yYq24ZsbGKJJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "e37dbd60-f233-4430-c3b8-bffdf6552bf1"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(valid_accuracy)\n",
        "print(training_accuracy)\n",
        "plt.plot(training_accuracy,'-o')\n",
        "plt.plot(valid_accuracy,'-o')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(['Train','Valid'])\n",
        "plt.title('Train vs Valid Accuracy')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ioUVvzTCVWuI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "f59a2fcc-8c75-40bc-e80c-af3876048c01"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[95.64802613404055, 95.91324796950107, 95.91324796950107, 96.33698512348748, 95.91324796950107, 95.91324796950107, 95.91324796950107, 95.9166114149953, 95.92343729856161, 95.93151123680866, 95.93846068843582, 95.99230908245391, 96.13631524630406, 96.37878473948837, 96.57787569601759, 96.7957887866733, 96.98322044412298, 97.1414983792843, 97.27804367644622, 97.39672007332686, 97.5013522846566, 97.58409887113929, 97.66557219605893, 97.73840885162471, 97.80346253500484, 97.86245942455385, 97.91594773718096, 97.96464740643631, 98.00949773227923, 98.0508426167652, 98.08892259240842, 98.12377649423895, 98.15655906403668, 98.18698855205102, 98.21529587746322, 98.24201394644271, 98.2671584288207, 98.290689294816, 98.31292516579687, 98.33392454653003, 98.3537206080841, 98.3724823079544, 98.39028492689607, 98.40721490501075, 98.42328774716269, 98.43870422744351, 98.45337441160339, 98.46736056846076, 98.48070576300631, 98.49345715044528, 98.50566590542142, 98.5173623122344, 98.52856540798658, 98.53939192370204, 98.54981318733361, 98.55983610972982, 98.56949915443275, 98.57879778207041, 98.58777008163695, 98.59641410257984, 98.60474888115365, 98.61276995621306, 98.62051964681581, 98.62797918440913, 98.63519574777519, 98.64213377350498, 98.64879139233307, 98.65519275481269, 98.66139424303894, 98.66738418300044, 98.67317584481931, 98.6787864033171, 98.68422855472348, 98.68951221711957, 98.6946337715031, 98.69960564119565]\n",
            "[95.35069769965278, 95.04167100694444, 95.33160590277778, 95.84117667518825, 95.23675130208333, 95.48503255208334, 96.55786024305556, 96.57786331976835, 96.60534195842324, 96.61549959531082, 96.63452876766665, 96.67281592219437, 96.73946337112454, 96.8519588261403, 97.01106739856174, 97.16790075598576, 97.31323771866535, 97.44143810431407, 97.55279844875606, 97.65083591657528, 97.73684067011517, 97.8082400209307, 97.87569301093765, 97.9365393756262, 97.99140342257405, 98.0409629752922, 98.08613358440427, 98.12719006214424, 98.16507615785522, 98.19978200405038, 98.2319105103054, 98.26156361305267, 98.2892465597321, 98.31511747533641, 98.33904188172257, 98.36177515135374, 98.3830240565169, 98.40314810281518, 98.42190661840887, 98.43980237829015, 98.45651094743303, 98.4726316042699, 98.4878855816017, 98.5022718474845, 98.51493295461647, 98.52801751149546, 98.54050424389793, 98.55237377966947, 98.563771979152, 98.57473086358651, 98.58521401257993, 98.59513464097255, 98.60478232039718, 98.61389565281097, 98.62277929827104, 98.63127909711386, 98.63936643677808, 98.64729722016335, 98.65480858168412, 98.66215234258647, 98.66917071321095, 98.67598535836498, 98.68244174691307, 98.68880344806783, 98.69491240722252, 98.7008555517258, 98.70659666929787, 98.71205741586827, 98.71742366464947, 98.72257406840745, 98.72767623520917, 98.73251839934228, 98.73730992312741, 98.7418891882766, 98.74634707576844, 98.75073653481253]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# app = FastAPI(title=\"ML Models as API on Google Colab\", description=\"with FastAPI and ColabCode\", version=\"1.0\")\n",
        "# @app.on_event(\"startup\")\n",
        "# @app.post(\"/api\", tags=[\"prediction\"])\n",
        "# def load_model():\n",
        "#     global model\n",
        "#     model = pickle.load(open(\"model_gb.pkl\", \"rb\"))"
      ],
      "metadata": {
        "id": "q-hq82sd3suj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TLNlr4wpBMAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.plot(loss,'-o')\n",
        "# plt.plot(val_losses,'-o')\n",
        "# plt.xlabel('epoch')\n",
        "# plt.ylabel('accuracy')\n",
        "# plt.legend(['Train','Valid'])\n",
        "# plt.title('Train vs Valid Accuracy')\n",
        "\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "OueWKQ-kBGQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change the name, for saving multiple files\n",
        "model_name = 'rnn_1_epoch.net'\n",
        "\n",
        "checkpoint = {'n_hidden': net.n_hidden,\n",
        "              'n_layers': net.n_layers,\n",
        "              'state_dict': net.state_dict()}\n",
        "\n",
        "with open(model_name, 'wb') as f:\n",
        "    torch.save(checkpoint, f)"
      ],
      "metadata": {
        "id": "iaqlzT_3ePVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we have loaded in a model that trained over 1 epoch `rnn_1_epoch.net`\n",
        "with open('rnn_1_epoch.net', 'rb') as f:\n",
        "    checkpoint = torch.load(f)\n",
        "    \n",
        "loaded = WordSegment(len(CHARS), len(POSTAGS), n_hidden=checkpoint['n_hidden'], n_layers=checkpoint['n_layers'])\n",
        "loaded.load_state_dict(checkpoint['state_dict'])"
      ],
      "metadata": {
        "id": "YcWAfGOafC4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "   loaded.cuda()"
      ],
      "metadata": {
        "id": "xrCMWGccf_r_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLHgfMvwxizb"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "2o_JFxuSMIXR"
      },
      "outputs": [],
      "source": [
        "# def segment(sample,net):\n",
        "#     net.eval()\n",
        "#     #sample ='ខ្ញុំទៅសាលារៀន'\n",
        "#     sample_chars = list(sample)\n",
        "#     sample_index = [chars2idx[x] for x in sample_chars ]\n",
        "#     sample_arr = torch.from_numpy(np.array(sample_index)).unsqueeze(0)\n",
        "#     sample_encoded = one_hot_encode(sample_arr,len(CHARS))\n",
        "\n",
        "#     if(train_on_gpu):\n",
        "#         sample_encoded = sample_encoded.cuda()\n",
        "\n",
        "#     h = net.init_hidden(1)\n",
        "\n",
        "#     h = tuple([each.data for each in h])\n",
        "#     outputs,_ = net(sample_encoded,h)\n",
        "#     outputs = torch.sigmoid(outputs)\n",
        "#     if(train_on_gpu):\n",
        "#         outputs  =outputs.detach().cpu().numpy()\n",
        "#     else:\n",
        "#         outputs  =outputs.detach().numpy()\n",
        "#     print(outputs)\n",
        "#     # idx = np.argmax(outputs, axis = 1)\n",
        "#     # print(idx)\n",
        "#     result = ''\n",
        "#     t = ''\n",
        "#     print(len(sample_chars))\n",
        "#     for i,c in enumerate(sample_chars):\n",
        "#       print(outputs[i])\n",
        "#       print(np.where(outputs[i] == max(outputs[i]), 1, 0))\n",
        "#       print(c)\n",
        "def segment(sample,net):\n",
        "    net.eval()\n",
        "    #sample ='ខ្ញុំទៅសាលារៀន'\n",
        "    sample_chars = list(sample)\n",
        "    sample_index = [chars2idx[x] for x in sample_chars ]\n",
        "    sample_arr = torch.from_numpy(np.array(sample_index)).unsqueeze(0)\n",
        "    sample_encoded = one_hot_encode(sample_arr,len(CHARS))\n",
        "\n",
        "    if(train_on_gpu):\n",
        "        sample_encoded = sample_encoded.cuda()\n",
        "\n",
        "    h = net.init_hidden(1)\n",
        "\n",
        "    h = tuple([each.data for each in h])\n",
        "    outputs,_ = net(sample_encoded,h)\n",
        "    outputs = torch.sigmoid(outputs)\n",
        "    print(len(outputs))\n",
        "    if(train_on_gpu):\n",
        "        outputs  =outputs.detach().cpu().numpy()\n",
        "    else:\n",
        "        outputs  =outputs.detach().numpy()\n",
        "    idx =(outputs>=0.5).astype(int)\n",
        "    predicts = one_hot.inverse_transform(idx)\n",
        "    print(predicts)\n",
        "    result = ''\n",
        "    t = ''\n",
        "    for i, c in enumerate(sample_chars):\n",
        "        print(len(predicts[i]))\n",
        "        if (predicts[i][0] !=1):\n",
        "            # if result =='':\n",
        "            #     result +=c\n",
        "                # t = idx2tags[predicts[i][0]]\n",
        "            if(len(predicts[i])==2):\n",
        "                result +=t + ' ' +c\n",
        "                t= idx2tags[predicts[i][1]]\n",
        "            else:\n",
        "                result +='_'+ t + ' ' +c\n",
        "                t = idx2tags[predicts[i][0]]\n",
        "        else:\n",
        "            result +=c\n",
        "    return result+'_'+ t\n",
        "\n",
        "    # for i,c in enumerate(sample_chars):\n",
        "    #     if idx[i] != 1:\n",
        "    #         if result =='':\n",
        "    #             result +=c\n",
        "    #             t = idx2tags[idx[i]]\n",
        "    #         else:\n",
        "    #             result +='_'+ t + ' ' +c\n",
        "    #             t = idx2tags[idx[i]]\n",
        "    #     else:\n",
        "    #         result +=c\n",
        "    # return result+'_'+ t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "e-DpC-DEB0Cl"
      },
      "outputs": [],
      "source": [
        "# samples ='អាវថ្មី'\n",
        "samples = 'ចូរថែសុខភាពរបស់ខ្លួនឱ្យបានល្អត្រូវចេះអាណិតស្រឡាញ់ខ្លួនឱ្យបានច្រើនអាណិតស្រឡាញ់ដល់ក្រុមគ្រួសារគិតគូរដល់ទឹកចិត្តអ្នកដែលអាណិតស្រឡាញ់យើងនិងខ្លាចបាត់បង់យើងព្រោះបញ្ហាទាំងឡាយដែលបានកើតឡើងចំពោះជីវិតយើងហើយនោះទោះបីជាល្អក្តីអាក្រក់ក្តីវាមិនអាចសារត្រលប់ថយក្រោយដូចខ្សែអាត់សំឡេងឬខ្សែវីដេអូបាននោះទេ។'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(np.argmax([[80, -0.36012337, -0.40979862, -0.4940329,  -0.41396353], [2, 3, 4], [10, 20, 30]], axis = 0))\n",
        "print(POSTAGS)"
      ],
      "metadata": {
        "id": "I9EN6RCqoFhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "tgA-E-358k90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dcc5359e-ceb1-4b72-c365-e42c4d5cec59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "282\n",
            "[(2,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,), (1,)]\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'_ ចូរថែសុខភាពរបស់ខ្លួនឱ្យបានល្អត្រូវចេះអាណិតស្រឡាញ់ខ្លួនឱ្យបានច្រើនអាណិតស្រឡាញ់ដល់ក្រុមគ្រួសារគិតគូរដល់ទឹកចិត្តអ្នកដែលអាណិតស្រឡាញ់យើងនិងខ្លាចបាត់បង់យើងព្រោះបញ្ហាទាំងឡាយដែលបានកើតឡើងចំពោះជីវិតយើងហើយនោះទោះបីជាល្អក្តីអាក្រក់ក្តីវាមិនអាចសារត្រលប់ថយក្រោយដូចខ្សែអាត់សំឡេងឬខ្សែវីដេអូបាននោះទេ។_n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 130
        }
      ],
      "source": [
        "segment(samples, net)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "segment(samples, loaded)"
      ],
      "metadata": {
        "id": "oq_xPAUtfzWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(data[0]))"
      ],
      "metadata": {
        "id": "9zfYAnotcJkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWYPpbiGx6Ly"
      },
      "source": [
        "# Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def predict(test_dl, net):\n",
        "#     net.eval()\n",
        "#     test_result =[]\n",
        "#     for x, y in test_dl:\n",
        "#       x = one_hot_encode(x, len(CHARS))\n",
        "#       batch_size = x.shape[0]\n",
        "\n",
        "#       if(train_on_gpu):\n",
        "#           sample_encoded = x.cuda()\n",
        "\n",
        "#       h = net.init_hidden(batch_size)\n",
        "\n",
        "#       h = tuple([each.data for each in h])\n",
        "#       outputs,_ = net(sample_encoded,h)\n",
        "#       if(train_on_gpu):\n",
        "#           outputs  =outputs.detach().cpu().numpy()\n",
        "#       else:\n",
        "#           outputs  =outputs.detach().numpy()\n",
        "      \n",
        "#       idx = np.argmax(outputs, axis=1)\n",
        "#       test_result = [idx2tags[idx[i]] for i in idx]\n",
        "#       print(test_result)\n",
        "      "
      ],
      "metadata": {
        "id": "FYZaOo4kPLDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict(test_dl, net)"
      ],
      "metadata": {
        "id": "6pRsSDQZRiCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def accuracy(samples):\n",
        "#   pos_count = {pos: {\"correct\": 0, \"corpus\": 0} for pos in POSTAGS}\n",
        "#   for sample in samples:\n",
        "pos_count = {pos: {\"correct\": 0, \"corpus\": 0} for pos in POSTAGS}\n",
        "for num, sentence_tag in enumerate(tag_clean_all):\n",
        "  for i, tag in enumerate(sentence_tag):\n",
        "    tag_index = tags2idx[tag]\n",
        "    pos_count[idx2tags[tag_index]][\"corpus\"] += 1\n",
        "for num, sentence_tag in enumerate(tag_clean_all):\n",
        "  for i, tag in enumerate(sentence_tag):\n",
        "    tag_index = tags2idx[tag]\n",
        "    pos_count[idx2tags[tag_index]][\"correct\"] += 1\n",
        "print(pos_count)\n"
      ],
      "metadata": {
        "id": "QMPlj4GEAAaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nototal_correct = 0\n",
        "total_corpus = 0\n",
        "for pos in pos_count:\n",
        "  if pos not in [\"ns\"]:\n",
        "    correct = pos_count[pos][\"correct\"]\n",
        "    corpus = pos_count[pos][\"corpus\"]\n",
        "    total_corpus += pos_count[pos][\"corpus\"]\n",
        "    total_correct += pos_count[pos][\"correct\"]\n",
        "    accuracy = round((correct / corpus)*100, 2)\n",
        "    print(f\"-- {pos}: {accuracy} | correct: {correct}, corpus: {corpus}\")\n",
        "\n",
        "accuracy = round((total_correct / total_corpus)*100, 2)\n",
        "print(f\"AVERAGE ACCURACY: {accuracy}\")"
      ],
      "metadata": {
        "id": "z7T553FnAGMP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Final_Version_#2.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}